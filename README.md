# HAM10000-EfficientNetB1-Skin-Lesion-Classification
Skin lesion classification using EfficientNetB1 with transfer learning on the HAM10000 dataset. The project addresses class imbalance with weighted loss and data augmentation, achieving improved accuracy and robustness compared to previous CNN-based models.

In this approach, we implemented a skin lesion classification pipeline using EfficientNetB1as the backbone model and applied transfer learning on the HAM10000 dataset. The dataset was first loaded along with its metadata, and each dermoscopic image was mapped to its corresponding label. The seven diagnostic categories were encoded into numerical labels, and the data was split into training (80%) and validation (20%) sets using stratified sampling to preserve class distribution. Due to the severe class imbalance in HAM10000, class weights were computed and applied during training to ensure that underrepresented classes contributed more effectively to the loss function.

A `tf.data.Dataset` pipeline was built to efficiently load, decode, resize, batch, and prefetch images. To improve generalization, extensive data augmentation was applied, including random flips, rotations, zooming, brightness, and contrast adjustments. EfficientNetB1 pre-trained on ImageNet was used as the base model with its top layers removed. The base network was frozen, and a lightweight classification head consisting of global average pooling, dropout, and a softmax layer was added. This design significantly reduced the number of trainable parameters while maintaining strong representational power.

The model was trained using the Adam optimizer and sparse categorical cross-entropy loss, with EarlyStopping based on validation loss. The final evaluation on the validation set achieved a validation accuracy of 68.10%  with a validation loss of 0.8849. The weighted F1-score reached approximately 0.71, indicating strong overall performance. Importantly, recall for minority classes such as `df` and `vasc` improved compared to earlier models, while the dominant `nv` class maintained high precision and recall.

When compared to the previously implemented DenseNet121-based model, EfficientNetB1 demonstrated higher accuracy, better stability, and substantially fewer parameters. Compared to the ConvNeXt-Small model, this approach showed improved robustness and reduced overfitting, particularly on rare classes. In comparison with InceptionResNetV2, EfficientNetB1 achieved better performance despite being significantly lighter, with far lower computational and memory requirements. Overall, EfficientNetB1 provided the best balance between accuracy, efficiency, and generalization among all evaluated architectures. The implementation details of the DenseNet121, ConvNeXt-Small, and InceptionResNetV2 models are available in separate GitHub repositories provided earlier.

The dataset used in this work is the HAM10000 (Human Against Machine with 10000 training images) skin lesion dataset, available at:
https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000
